Stuff to do and how to do them:

1. We need to read data from the emulator. Using the record.py and utils.py files from the TensorKart repo seems to be the best way to go. No clue what else I can do just yet.

2. Feed the data into the neural net. I'm considering a very simple convolutional network with 2 hidden layers(each having convolution and maxpooling layers) 

3. Output will be decided by the neural net. This output will be given as input to the emulator.


Training data will be images of gameplay with the corresponding controller input.

For the ML algorithm, we'll use a Neural Network.

We'll start with a simple Neural Net, with one hidden layer.

This is not expected to be efficient or capable, but it provides a starting point for the algo. It will be interesting to see how the AI improves as we improve the algorithm using various tactics.
We'll then move on to a simple convolutional NN with 2 hidden layers.

We'll improve this algo using various techniques:
-pooling
-dropout
-decaying learning rate
-different activation functions
-other hyper parameters.

Training data shall be a playthrough of World-1.
Testing will be done on the rest of the worlds.
The algo will be considered complete when the game can play through the rest of Worlds on it's own.


Lua script to pause the emu and give control to us
It calls other lua scripts
	Nested Lua script which takes a SS, inputs it to our program and gets the output
	This o/p is given to the emu
End


Test if nested lua scripting works inside the emulator

